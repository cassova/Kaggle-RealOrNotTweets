{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real or Not?  NLP with Disaster Tweets with Deep Learning\n",
    "\n",
    "Some resources I used:\n",
    " - https://www.kaggle.com/philculliton/nlp-getting-started-tutorial\n",
    " - https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has 7613 records\n",
      "Test has 3263 records\n",
      "\n",
      "Keyword Values: Train = 0.801% Test = 0.797%\n",
      "Location Values: Train = 33.272% Test = 33.865%\n"
     ]
    }
   ],
   "source": [
    "print (f'Train has {len(train_df)} records\\nTest has {len(test_df)} records\\n')\n",
    "\n",
    "null_train_keyword = train_df['keyword'].isnull().sum() / len(train_df) * 100\n",
    "null_test_keyword = test_df['keyword'].isnull().sum() / len(test_df) * 100\n",
    "null_train_location = train_df['location'].isnull().sum() / len(train_df) * 100\n",
    "null_test_location = test_df['location'].isnull().sum() / len(test_df) * 100\n",
    "\n",
    "print (f'Keyword Values: Train = {round(null_train_keyword,3)}% Test = {round(null_test_keyword,3)}%')\n",
    "print (f'Location Values: Train = {round(null_train_location,3)}% Test = {round(null_test_location,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train contains 61 records with no keywords\n",
      "  21 of which don't have any '#'\n"
     ]
    }
   ],
   "source": [
    "# Let's see if we can use a '#' value for our keyword...\n",
    "null_train_keyword_df = train_df[train_df['keyword'].isnull()]['text'].str.contains('#')\n",
    "\n",
    "print(f'Train contains {len(null_train_keyword_df)} records with no keywords')\n",
    "print(f'  {null_train_keyword_df.sum()} of which don\\'t have any \\'#\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This is ALL CAPS <allcaps> too longggg\n",
       "Name: test, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing area:\n",
    "eyes = r\"[8:=;]\"\n",
    "nose = r\"['`\\-]?\"\n",
    "df = pd.DataFrame({'test': ['This is ALL CAPS too longggg']})\n",
    "df['test'].str.replace(r\" ([A-Z -_]{2,}) \", r' \\1 <allcaps> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes = r\"[8:=;]\"\n",
    "nose = r\"['`\\-]?\"\n",
    "key_words = ['user', 'number', 'hashtag', 'repeat', 'smile', \n",
    "             'lolface', 'sadface', 'neutralface', 'heart',\n",
    "             'elong', 'allcaps', 'url']\n",
    "\n",
    "all_data = [train_df, test_df]\n",
    "\n",
    "for df in all_data:\n",
    "    # Replace websites URLs\n",
    "    df['text'] = df['text'].str.replace('http\\S+|www.\\S+', '<url>', case=False)\n",
    "    # Replace usernames\n",
    "    df['text'] = df['text'].str.replace('@\\S+', ' <user>')\n",
    "    # Remove encodings like &amp; and &gt;\n",
    "    df['text'] = df['text'].str.replace('&\\S+;', '') # not used in GloVe\n",
    "    # Replace numbers\n",
    "    df['text'] = df['text'].str.replace(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    # Replace hashtags\n",
    "    df['text'] = df['text'].str.replace('#', '<hashtag> ')\n",
    "    # Replace repeat !! ?? (not words)\n",
    "    #df['text'] = df['text'].str.replace(r'(?<!\\S)((\\S+))(?:\\s+\\2)+(?!\\S)', r'\\1 <repeat>') # words: my misunderstanding\n",
    "    df['text'] = df['text'].str.replace(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    # Replace emoticons\n",
    "    df['text'] = df['text'].str.replace(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    df['text'] = df['text'].str.replace(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    df['text'] = df['text'].str.replace(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    df['text'] = df['text'].str.replace(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    df['text'] = df['text'].str.replace(r\"<3\",\"<heart>\")\n",
    "    # Elongated words like wayyyyy too longgg\n",
    "    df['text'] = df['text'].str.replace(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    # ALL CAPS\n",
    "    df['text'] = df['text'].str.replace(r\" ([A-Z -_]{2,}) \", r' \\1 <allcaps> ')\n",
    "    # Remove *\n",
    "    df['text'] = df['text'].str.replace(r\"\\*\", r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = 5077 records\n",
      "Validate = 2536 records\n"
     ]
    }
   ],
   "source": [
    "xtrain_full = train_df['text']\n",
    "xtest_full = test_df['text']\n",
    "ytrain_full = train_df['target']\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text.values, ytrain_full, \n",
    "                                                  stratify=ytrain_full, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.333, shuffle=True)\n",
    "\n",
    "print(f'Train = {len(xtrain)} records\\nValidate = {len(xvalid)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e88f93c80a46028c3bf1f6e10a3b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # This is an awesome library that shows the progress of whatever tqdm() is applied to\n",
    "\n",
    "#with open('D:\\Datasets\\GloVe\\glove.twitter.27B.25d.txt', 'r', encoding=\"utf8\") as f:\n",
    "with open('D:\\Datasets\\GloVe\\glove.twitter.27B.200d.txt', 'r', encoding=\"utf8\") as f:\n",
    "    embeddings_index = {}\n",
    "    for line in tqdm(f):\n",
    "        vals = line.rstrip().split(' ')\n",
    "        embeddings_index[vals[0]] = [float(x) for x in vals[1:]]\n",
    "print('Found %s word vectors.' % len(embeddings_index))  #1193514 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screams internally\n",
      "['screams', 'internally']\n",
      "['screams', 'internally']\n",
      "[ 6.70529390e-02  4.43065556e-02  1.49141888e-02  7.36671104e-02\n",
      " -1.34542076e-02  1.14275995e-01  1.26520787e-01  1.63734215e-01\n",
      "  5.48288245e-04 -8.43475034e-02 -1.92787878e-02 -2.65030936e-02\n",
      " -1.26914694e-01 -4.21059174e-02  8.09426895e-03 -1.06641128e-01\n",
      "  4.30478317e-02 -5.17430657e-02 -3.90803207e-02 -1.33606430e-02\n",
      "  4.97997301e-02  3.16750330e-02  3.06803763e-02 -2.51013095e-02\n",
      "  1.32639909e-02  3.05011067e-01 -2.26566550e-03 -1.80953834e-02\n",
      " -4.70629671e-02  2.87402219e-02 -8.27007674e-02  6.32664753e-02\n",
      "  3.09941918e-02 -1.90176491e-02 -1.21079073e-01 -6.06447967e-02\n",
      " -3.78739929e-02 -2.74410781e-02  1.02910710e-01  4.38003714e-02\n",
      "  1.67318672e-01 -5.89269517e-02 -2.62017222e-02  1.21699406e-01\n",
      " -1.46393897e-01  6.78174549e-02  7.50682395e-02  4.48230318e-02\n",
      " -6.71260129e-02  1.42124547e-02 -8.80199119e-02  7.07095350e-02\n",
      "  1.15412804e-02  1.74016958e-02  2.89707930e-02 -1.28155360e-02\n",
      " -1.01446424e-01  8.62075666e-02  5.54164099e-02  6.70174780e-02\n",
      "  2.72216693e-02 -6.37558179e-02  7.49648506e-02 -5.51787559e-02\n",
      " -4.70788731e-02 -2.73114912e-02 -2.95476839e-02  1.79194820e-02\n",
      "  2.92123486e-03  1.41502343e-01  1.73452764e-02  8.73518610e-03\n",
      " -3.09218664e-02 -7.17930125e-02  4.18079143e-02  1.05770042e-01\n",
      "  1.14547332e-02 -9.12553739e-03 -1.03898751e-01  5.67160214e-02\n",
      " -1.06851648e-01  4.08175336e-02 -4.12151829e-03 -5.85143320e-02\n",
      " -7.82775970e-02 -1.58583486e-01 -4.46031552e-02  4.98568045e-02\n",
      " -9.11646163e-02  8.25763265e-02 -1.87040208e-02  3.24378928e-02\n",
      "  4.92738973e-02  2.61308938e-02  7.10061347e-03 -8.84418880e-03\n",
      " -8.81593230e-02 -1.49831459e-01  4.51944831e-02 -3.51980469e-02\n",
      " -4.06034111e-02  4.25550272e-02 -3.23518134e-02  1.86829687e-02\n",
      "  1.02453179e-03 -4.35084500e-02 -5.51142899e-02  6.50133254e-02\n",
      " -1.75505570e-02 -2.82332892e-02  1.00180496e-01 -4.68327983e-02\n",
      "  2.71561741e-02 -6.59920106e-02  7.70850233e-02  3.23845610e-02\n",
      " -6.74949379e-02 -1.20249156e-02  6.57655844e-02  7.66431179e-03\n",
      "  9.26541639e-02  3.43844096e-02 -1.80050000e-02 -2.42969351e-02\n",
      " -4.32119439e-02  1.01570865e-01 -5.99729097e-02  1.04782936e-02\n",
      "  2.02710398e-01 -1.11711391e-01 -1.05464086e-01  1.94254034e-02\n",
      " -6.77266973e-02  1.05529581e-01 -1.04841882e-02  1.75379258e-02\n",
      "  4.57717764e-03  2.52426855e-02  1.47644855e-03  3.14844700e-02\n",
      " -4.49596361e-02  1.65549245e-02 -1.33758941e-01 -4.27500438e-02\n",
      "  5.02815875e-03 -7.57348869e-02 -5.22127598e-02 -1.06630836e-01\n",
      " -1.48149168e-02 -1.67265341e-02 -6.28697617e-02  7.77081632e-02\n",
      " -2.04229886e-01 -1.39757364e-01  5.80801925e-03 -4.63537478e-02\n",
      "  2.73194442e-02  7.45709439e-02  1.32630552e-01  5.62423041e-02\n",
      " -6.41076206e-03 -7.66789531e-02  3.21486848e-02 -1.20965860e-01\n",
      "  4.24806434e-02 -4.27767752e-02 -3.80152754e-03 -5.03049787e-02\n",
      " -3.49014473e-02 -3.50799684e-02  6.72832013e-02 -2.11053548e-02\n",
      "  4.58887320e-02 -7.04943366e-02  1.65853452e-01  2.13056765e-02\n",
      " -1.22105476e-02 -8.67249785e-03 -7.91584136e-02  1.78660567e-02\n",
      "  3.03693678e-02  1.02433530e-01  6.92243195e-02  3.42857926e-02\n",
      " -2.83547359e-02 -7.31939545e-02  3.90706835e-02 -2.09453595e-02\n",
      " -1.31224277e-02 -5.54416723e-02 -3.67758259e-03  8.24135242e-02\n",
      " -3.64069009e-02 -5.95267004e-02  1.64673603e-04  2.51293789e-02\n",
      "  1.00709136e-02  1.08393592e-01 -9.34213932e-02  1.04140148e-02]\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import re\n",
    "\n",
    "def new_tokenize(s):\n",
    "    # This will regroup key_words like '<', 'hashtag', '>' into '<hashtag>'\n",
    "    words = word_tokenize(s)\n",
    "    new_words = []\n",
    "    skip = 0\n",
    "    for i, w in enumerate(words):\n",
    "        if skip > 0:\n",
    "            skip = skip-1\n",
    "        else:\n",
    "            if w == '<' and words[i+1] in key_words and words[i+2] == '>':\n",
    "                new_words.append('<' + words[i+1] + '>')\n",
    "                skip = 2\n",
    "            else:\n",
    "                new_words.append(w)\n",
    "    return new_words\n",
    "            \n",
    "\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = new_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha() or re.match(\"<\\S+>\",w)]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            # This adds the np.array (size=25) of values from the GloVe file for each word to the matrix\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    \n",
    "    # Now we sum up each column to create a vector of size 25\n",
    "    v = M.sum(axis=0)\n",
    "    \n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "    # I don't understand what the heck this is doing...\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "\n",
    "# Print an example to show what this does...\n",
    "s = xtrain[1973]\n",
    "print (s)\n",
    "print (word_tokenize(s))\n",
    "print (new_tokenize(s))\n",
    "print (sent2vec(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df223f3dbc344acab812b6f91194065e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5077.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8eafb2355749df9e300da4e88e2cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a9da440d8e4fa388db5c6790cb091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7613.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5293cd35d01542fb9ea451ba62507af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3263.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]\n",
    "xtrain_full_glove = [sent2vec(x) for x in tqdm(xtrain_full)]\n",
    "xtest_full_glove = [sent2vec(x) for x in tqdm(xtest_full)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove_np = np.stack(xtrain_glove)\n",
    "xvalid_glove_np = np.stack(xvalid_glove)\n",
    "xtrain_full_glove_np = np.stack(xtrain_full_glove)\n",
    "xtest_full_glove_np = np.stack(xtest_full_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from keras import callbacks\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# scale the data before any neural net:\n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove_np)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove_np)\n",
    "xtrain_glove_full_scl = scl.fit_transform(xtrain_full_glove_np)\n",
    "xtest_glove_full_scl = scl.transform(xtest_full_glove_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = xtrain_glove_scl.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)\n",
    "ytrain_full_enc = np_utils.to_categorical(ytrain_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=input_size, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Smaller Set with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1368 - acc: 0.9447 - f1_m: 0.9447 - precision_m: 0.9447 - recall_m: 0.9447 - val_loss: 0.1075 - val_acc: 0.9610 - val_f1_m: 0.9611 - val_precision_m: 0.9611 - val_recall_m: 0.9611\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1281 - acc: 0.9494 - f1_m: 0.9490 - precision_m: 0.9490 - recall_m: 0.9490 - val_loss: 0.1120 - val_acc: 0.9586 - val_f1_m: 0.9587 - val_precision_m: 0.9587 - val_recall_m: 0.9587\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1154 - acc: 0.9551 - f1_m: 0.9547 - precision_m: 0.9547 - recall_m: 0.9547 - val_loss: 0.1208 - val_acc: 0.9539 - val_f1_m: 0.9541 - val_precision_m: 0.9541 - val_recall_m: 0.9541\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1178 - acc: 0.9547 - f1_m: 0.9547 - precision_m: 0.9547 - recall_m: 0.9547 - val_loss: 0.1396 - val_acc: 0.9448 - val_f1_m: 0.9448 - val_precision_m: 0.9448 - val_recall_m: 0.9448\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1187 - acc: 0.9537 - f1_m: 0.9533 - precision_m: 0.9533 - recall_m: 0.9533 - val_loss: 0.1476 - val_acc: 0.9444 - val_f1_m: 0.9447 - val_precision_m: 0.9447 - val_recall_m: 0.9447\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1093 - acc: 0.9561 - f1_m: 0.9552 - precision_m: 0.9552 - recall_m: 0.9552 - val_loss: 0.1504 - val_acc: 0.9397 - val_f1_m: 0.9400 - val_precision_m: 0.9400 - val_recall_m: 0.9400\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - acc: 0.9616 - f1_m: 0.9611 - precision_m: 0.9611 - recall_m: 0.9611 - val_loss: 0.1555 - val_acc: 0.9393 - val_f1_m: 0.9396 - val_precision_m: 0.9396 - val_recall_m: 0.9396\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1016 - acc: 0.9600 - f1_m: 0.9604 - precision_m: 0.9604 - recall_m: 0.9604 - val_loss: 0.1671 - val_acc: 0.9314 - val_f1_m: 0.9318 - val_precision_m: 0.9318 - val_recall_m: 0.9318\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1095 - acc: 0.9594 - f1_m: 0.9598 - precision_m: 0.9598 - recall_m: 0.9598 - val_loss: 0.1792 - val_acc: 0.9294 - val_f1_m: 0.9298 - val_precision_m: 0.9298 - val_recall_m: 0.9298\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0976 - acc: 0.9602 - f1_m: 0.9601 - precision_m: 0.9601 - recall_m: 0.9601 - val_loss: 0.2097 - val_acc: 0.9188 - val_f1_m: 0.9193 - val_precision_m: 0.9193 - val_recall_m: 0.9193\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0978 - acc: 0.9638 - f1_m: 0.9633 - precision_m: 0.9633 - recall_m: 0.9633 - val_loss: 0.1907 - val_acc: 0.9267 - val_f1_m: 0.9269 - val_precision_m: 0.9269 - val_recall_m: 0.9269\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0922 - acc: 0.9636 - f1_m: 0.9635 - precision_m: 0.9635 - recall_m: 0.9635 - val_loss: 0.2075 - val_acc: 0.9227 - val_f1_m: 0.9232 - val_precision_m: 0.9232 - val_recall_m: 0.9232\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0958 - acc: 0.9645 - f1_m: 0.9648 - precision_m: 0.9648 - recall_m: 0.9648 - val_loss: 0.2303 - val_acc: 0.9101 - val_f1_m: 0.9105 - val_precision_m: 0.9105 - val_recall_m: 0.9105\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0959 - acc: 0.9630 - f1_m: 0.9625 - precision_m: 0.9625 - recall_m: 0.9625 - val_loss: 0.2304 - val_acc: 0.9038 - val_f1_m: 0.9042 - val_precision_m: 0.9042 - val_recall_m: 0.9042\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0947 - acc: 0.9628 - f1_m: 0.9627 - precision_m: 0.9627 - recall_m: 0.9627 - val_loss: 0.2346 - val_acc: 0.9069 - val_f1_m: 0.9073 - val_precision_m: 0.9073 - val_recall_m: 0.9073\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - acc: 0.9590 - f1_m: 0.9586 - precision_m: 0.9586 - recall_m: 0.9586 - val_loss: 0.2374 - val_acc: 0.9089 - val_f1_m: 0.9093 - val_precision_m: 0.9093 - val_recall_m: 0.9093\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0911 - acc: 0.9645 - f1_m: 0.9640 - precision_m: 0.9640 - recall_m: 0.9640 - val_loss: 0.2612 - val_acc: 0.8987 - val_f1_m: 0.8991 - val_precision_m: 0.8991 - val_recall_m: 0.8991\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0911 - acc: 0.9667 - f1_m: 0.9662 - precision_m: 0.9662 - recall_m: 0.9662 - val_loss: 0.2598 - val_acc: 0.9026 - val_f1_m: 0.9033 - val_precision_m: 0.9033 - val_recall_m: 0.9033\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0838 - acc: 0.9661 - f1_m: 0.9660 - precision_m: 0.9660 - recall_m: 0.9660 - val_loss: 0.2634 - val_acc: 0.8943 - val_f1_m: 0.8948 - val_precision_m: 0.8948 - val_recall_m: 0.8948\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0778 - acc: 0.9689 - f1_m: 0.9683 - precision_m: 0.9683 - recall_m: 0.9683 - val_loss: 0.2564 - val_acc: 0.9069 - val_f1_m: 0.9073 - val_precision_m: 0.9073 - val_recall_m: 0.9073\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0841 - acc: 0.9659 - f1_m: 0.9654 - precision_m: 0.9654 - recall_m: 0.9654 - val_loss: 0.2770 - val_acc: 0.8908 - val_f1_m: 0.8911 - val_precision_m: 0.8911 - val_recall_m: 0.8911\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0865 - acc: 0.9675 - f1_m: 0.9674 - precision_m: 0.9674 - recall_m: 0.9674 - val_loss: 0.2856 - val_acc: 0.8959 - val_f1_m: 0.8962 - val_precision_m: 0.8962 - val_recall_m: 0.8962\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0778 - acc: 0.9669 - f1_m: 0.9660 - precision_m: 0.9660 - recall_m: 0.9660 - val_loss: 0.2765 - val_acc: 0.8983 - val_f1_m: 0.8987 - val_precision_m: 0.8988 - val_recall_m: 0.8988\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0880 - acc: 0.9638 - f1_m: 0.9633 - precision_m: 0.9633 - recall_m: 0.9633 - val_loss: 0.3082 - val_acc: 0.8841 - val_f1_m: 0.8847 - val_precision_m: 0.8847 - val_recall_m: 0.8847\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0908 - acc: 0.9632 - f1_m: 0.9631 - precision_m: 0.9631 - recall_m: 0.9631 - val_loss: 0.3033 - val_acc: 0.8841 - val_f1_m: 0.8847 - val_precision_m: 0.8847 - val_recall_m: 0.8847\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0947 - acc: 0.9624 - f1_m: 0.9627 - precision_m: 0.9627 - recall_m: 0.9627 - val_loss: 0.3128 - val_acc: 0.8853 - val_f1_m: 0.8856 - val_precision_m: 0.8856 - val_recall_m: 0.8856\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0898 - acc: 0.9655 - f1_m: 0.9658 - precision_m: 0.9658 - recall_m: 0.9658 - val_loss: 0.3170 - val_acc: 0.8884 - val_f1_m: 0.8892 - val_precision_m: 0.8892 - val_recall_m: 0.8892\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0764 - acc: 0.9703 - f1_m: 0.9701 - precision_m: 0.9701 - recall_m: 0.9701 - val_loss: 0.3258 - val_acc: 0.8912 - val_f1_m: 0.8915 - val_precision_m: 0.8915 - val_recall_m: 0.8915\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0866 - acc: 0.9647 - f1_m: 0.9646 - precision_m: 0.9646 - recall_m: 0.9646 - val_loss: 0.3410 - val_acc: 0.8782 - val_f1_m: 0.8786 - val_precision_m: 0.8786 - val_recall_m: 0.8786\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0812 - acc: 0.9661 - f1_m: 0.9656 - precision_m: 0.9656 - recall_m: 0.9656 - val_loss: 0.3430 - val_acc: 0.8821 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0832 - acc: 0.9663 - f1_m: 0.9662 - precision_m: 0.9662 - recall_m: 0.9662 - val_loss: 0.3434 - val_acc: 0.8872 - val_f1_m: 0.8878 - val_precision_m: 0.8878 - val_recall_m: 0.8878\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0778 - acc: 0.9689 - f1_m: 0.9691 - precision_m: 0.9691 - recall_m: 0.9691 - val_loss: 0.3401 - val_acc: 0.8853 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
      "Epoch 33/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0794 - acc: 0.9655 - f1_m: 0.9650 - precision_m: 0.9650 - recall_m: 0.9650 - val_loss: 0.3619 - val_acc: 0.8770 - val_f1_m: 0.8774 - val_precision_m: 0.8774 - val_recall_m: 0.8774\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0894 - acc: 0.9665 - f1_m: 0.9656 - precision_m: 0.9656 - recall_m: 0.9656 - val_loss: 0.3610 - val_acc: 0.8778 - val_f1_m: 0.8782 - val_precision_m: 0.8782 - val_recall_m: 0.8782\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0771 - acc: 0.9687 - f1_m: 0.9685 - precision_m: 0.9685 - recall_m: 0.9685 - val_loss: 0.3659 - val_acc: 0.8730 - val_f1_m: 0.8735 - val_precision_m: 0.8735 - val_recall_m: 0.8735\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0772 - acc: 0.9681 - f1_m: 0.9680 - precision_m: 0.9680 - recall_m: 0.9680 - val_loss: 0.3863 - val_acc: 0.8663 - val_f1_m: 0.8671 - val_precision_m: 0.8671 - val_recall_m: 0.8671\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0671 - acc: 0.9724 - f1_m: 0.9727 - precision_m: 0.9727 - recall_m: 0.9727 - val_loss: 0.3852 - val_acc: 0.8715 - val_f1_m: 0.8720 - val_precision_m: 0.8720 - val_recall_m: 0.8720\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0786 - acc: 0.9687 - f1_m: 0.9685 - precision_m: 0.9685 - recall_m: 0.9685 - val_loss: 0.3680 - val_acc: 0.8715 - val_f1_m: 0.8715 - val_precision_m: 0.8715 - val_recall_m: 0.8715\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0702 - acc: 0.9693 - f1_m: 0.9695 - precision_m: 0.9695 - recall_m: 0.9695 - val_loss: 0.3805 - val_acc: 0.8715 - val_f1_m: 0.8720 - val_precision_m: 0.8720 - val_recall_m: 0.8720\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0715 - acc: 0.9707 - f1_m: 0.9701 - precision_m: 0.9701 - recall_m: 0.9701 - val_loss: 0.4000 - val_acc: 0.8683 - val_f1_m: 0.8686 - val_precision_m: 0.8686 - val_recall_m: 0.8686\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0638 - acc: 0.9740 - f1_m: 0.9734 - precision_m: 0.9734 - recall_m: 0.9734 - val_loss: 0.4188 - val_acc: 0.8600 - val_f1_m: 0.8602 - val_precision_m: 0.8602 - val_recall_m: 0.8602\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0722 - acc: 0.9726 - f1_m: 0.9721 - precision_m: 0.9721 - recall_m: 0.9721 - val_loss: 0.4357 - val_acc: 0.8616 - val_f1_m: 0.8617 - val_precision_m: 0.8617 - val_recall_m: 0.8617\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.9663 - f1_m: 0.9658 - precision_m: 0.9658 - recall_m: 0.9658 - val_loss: 0.4216 - val_acc: 0.8632 - val_f1_m: 0.8633 - val_precision_m: 0.8633 - val_recall_m: 0.8633\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0776 - acc: 0.9720 - f1_m: 0.9715 - precision_m: 0.9715 - recall_m: 0.9715 - val_loss: 0.4051 - val_acc: 0.8600 - val_f1_m: 0.8604 - val_precision_m: 0.8604 - val_recall_m: 0.8604\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0667 - acc: 0.9726 - f1_m: 0.9725 - precision_m: 0.9725 - recall_m: 0.9725 - val_loss: 0.4391 - val_acc: 0.8667 - val_f1_m: 0.8670 - val_precision_m: 0.8670 - val_recall_m: 0.8670\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0722 - acc: 0.9724 - f1_m: 0.9727 - precision_m: 0.9727 - recall_m: 0.9727 - val_loss: 0.4382 - val_acc: 0.8608 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0691 - acc: 0.9738 - f1_m: 0.9740 - precision_m: 0.9740 - recall_m: 0.9740 - val_loss: 0.4250 - val_acc: 0.8612 - val_f1_m: 0.8613 - val_precision_m: 0.8613 - val_recall_m: 0.8613\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0608 - acc: 0.9773 - f1_m: 0.9763 - precision_m: 0.9763 - recall_m: 0.9763 - val_loss: 0.4519 - val_acc: 0.8647 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0623 - acc: 0.9701 - f1_m: 0.9699 - precision_m: 0.9699 - recall_m: 0.9699 - val_loss: 0.4628 - val_acc: 0.8667 - val_f1_m: 0.8673 - val_precision_m: 0.8673 - val_recall_m: 0.8673\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0705 - acc: 0.9701 - f1_m: 0.9703 - precision_m: 0.9703 - recall_m: 0.9703 - val_loss: 0.4560 - val_acc: 0.8620 - val_f1_m: 0.8626 - val_precision_m: 0.8626 - val_recall_m: 0.8626\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0704 - acc: 0.9708 - f1_m: 0.9711 - precision_m: 0.9711 - recall_m: 0.9711 - val_loss: 0.4369 - val_acc: 0.8608 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24382600908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = callbacks.EarlyStopping(monitor='val_f1_m', patience=10)\n",
    "\n",
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=500, verbose=1, \n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc),\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Result:\t\t0.8310196266156057\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(f'Deep Result:\\t\\t{metrics.f1_score(model.predict(xvalid_glove_scl).argmax(axis=1), yvalid)}')  # Result: 0.7081524360829716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(xtest_glove_full_scl).argmax(axis=1)\n",
    "output = pd.DataFrame({'id': test_df.id, 'target': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Full Set with no Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3394 - acc: 0.8731 - f1_m: 0.8731 - precision_m: 0.8731 - recall_m: 0.8731\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2772 - acc: 0.8894 - f1_m: 0.8894 - precision_m: 0.8894 - recall_m: 0.8894\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2618 - acc: 0.8926 - f1_m: 0.8926 - precision_m: 0.8926 - recall_m: 0.8926\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2509 - acc: 0.8965 - f1_m: 0.8965 - precision_m: 0.8965 - recall_m: 0.8965\n",
      "Epoch 5/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2260 - acc: 0.9091 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091\n",
      "Epoch 6/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2248 - acc: 0.9054 - f1_m: 0.9055 - precision_m: 0.9055 - recall_m: 0.9055\n",
      "Epoch 7/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2262 - acc: 0.9075 - f1_m: 0.9075 - precision_m: 0.9075 - recall_m: 0.9075\n",
      "Epoch 8/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2052 - acc: 0.9149 - f1_m: 0.9149 - precision_m: 0.9149 - recall_m: 0.9149\n",
      "Epoch 9/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2009 - acc: 0.9182 - f1_m: 0.9181 - precision_m: 0.9181 - recall_m: 0.9181\n",
      "Epoch 10/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1998 - acc: 0.9171 - f1_m: 0.9171 - precision_m: 0.9171 - recall_m: 0.9171\n",
      "Epoch 11/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1997 - acc: 0.9172 - f1_m: 0.9172 - precision_m: 0.9172 - recall_m: 0.9172\n",
      "Epoch 12/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1881 - acc: 0.9242 - f1_m: 0.9242 - precision_m: 0.9242 - recall_m: 0.9242\n",
      "Epoch 13/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1733 - acc: 0.9333 - f1_m: 0.9332 - precision_m: 0.9332 - recall_m: 0.9332\n",
      "Epoch 14/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1808 - acc: 0.9263 - f1_m: 0.9263 - precision_m: 0.9263 - recall_m: 0.9263\n",
      "Epoch 15/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1706 - acc: 0.9306 - f1_m: 0.9307 - precision_m: 0.9307 - recall_m: 0.9307\n",
      "Epoch 16/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1711 - acc: 0.9317 - f1_m: 0.9317 - precision_m: 0.9317 - recall_m: 0.9317\n",
      "Epoch 17/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1525 - acc: 0.9423 - f1_m: 0.9423 - precision_m: 0.9423 - recall_m: 0.9423\n",
      "Epoch 18/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1626 - acc: 0.9348 - f1_m: 0.9348 - precision_m: 0.9348 - recall_m: 0.9348\n",
      "Epoch 19/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1599 - acc: 0.9351 - f1_m: 0.9351 - precision_m: 0.9351 - recall_m: 0.9351\n",
      "Epoch 20/20\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1477 - acc: 0.9409 - f1_m: 0.9409 - precision_m: 0.9409 - recall_m: 0.9409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2437fd63508>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = callbacks.EarlyStopping(monitor='val_f1_m', patience=10)\n",
    "\n",
    "model.fit(xtrain_glove_full_scl, y=ytrain_full_enc, batch_size=64, \n",
    "          epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Result:\t\t0.9665116279069768\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(f'Deep Result:\\t\\t{metrics.f1_score(model.predict(xvalid_glove_scl).argmax(axis=1), yvalid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(xtest_glove_full_scl).argmax(axis=1)\n",
    "output = pd.DataFrame({'id': test_df.id, 'target': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07956747, 0.98889416, 0.9997453 , ..., 1.        , 0.9980258 ,\n",
       "       0.14643204], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_values = model.predict(xtest_glove_full_scl)\n",
    "predict_values[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Learning with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model(input_size):\n",
    "    # create a simple 3 layer sequential neural net\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(300, input_dim=input_size, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6180 - acc: 0.7338 - f1_m: 0.7332 - precision_m: 0.7332 - recall_m: 0.7332 - val_loss: 0.4290 - val_acc: 0.8307 - val_f1_m: 0.8311 - val_precision_m: 0.8311 - val_recall_m: 0.8311\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4975 - acc: 0.7802 - f1_m: 0.7792 - precision_m: 0.7792 - recall_m: 0.7792 - val_loss: 0.4293 - val_acc: 0.8176 - val_f1_m: 0.8181 - val_precision_m: 0.8181 - val_recall_m: 0.8181\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4453 - acc: 0.8056 - f1_m: 0.8073 - precision_m: 0.8073 - recall_m: 0.8073 - val_loss: 0.4199 - val_acc: 0.8281 - val_f1_m: 0.8286 - val_precision_m: 0.8286 - val_recall_m: 0.8286\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4227 - acc: 0.8130 - f1_m: 0.8117 - precision_m: 0.8117 - recall_m: 0.8117 - val_loss: 0.4264 - val_acc: 0.8136 - val_f1_m: 0.8144 - val_precision_m: 0.8144 - val_recall_m: 0.8144\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3990 - acc: 0.8256 - f1_m: 0.8271 - precision_m: 0.8271 - recall_m: 0.8271 - val_loss: 0.4184 - val_acc: 0.8360 - val_f1_m: 0.8364 - val_precision_m: 0.8364 - val_recall_m: 0.8364\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3876 - acc: 0.8302 - f1_m: 0.8288 - precision_m: 0.8288 - recall_m: 0.8288 - val_loss: 0.4263 - val_acc: 0.8110 - val_f1_m: 0.8116 - val_precision_m: 0.8116 - val_recall_m: 0.8116\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3832 - acc: 0.8302 - f1_m: 0.8288 - precision_m: 0.8288 - recall_m: 0.8288 - val_loss: 0.4287 - val_acc: 0.8241 - val_f1_m: 0.8243 - val_precision_m: 0.8243 - val_recall_m: 0.8243\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3656 - acc: 0.8434 - f1_m: 0.8448 - precision_m: 0.8448 - recall_m: 0.8448 - val_loss: 0.4247 - val_acc: 0.8176 - val_f1_m: 0.8179 - val_precision_m: 0.8179 - val_recall_m: 0.8179\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3573 - acc: 0.8478 - f1_m: 0.8491 - precision_m: 0.8491 - recall_m: 0.8491 - val_loss: 0.4265 - val_acc: 0.8255 - val_f1_m: 0.8256 - val_precision_m: 0.8256 - val_recall_m: 0.8256\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3465 - acc: 0.8514 - f1_m: 0.8527 - precision_m: 0.8527 - recall_m: 0.8527 - val_loss: 0.4287 - val_acc: 0.8215 - val_f1_m: 0.8217 - val_precision_m: 0.8217 - val_recall_m: 0.8217\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3365 - acc: 0.8570 - f1_m: 0.8582 - precision_m: 0.8582 - recall_m: 0.8582 - val_loss: 0.4426 - val_acc: 0.8136 - val_f1_m: 0.8140 - val_precision_m: 0.8140 - val_recall_m: 0.8140\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3281 - acc: 0.8570 - f1_m: 0.8582 - precision_m: 0.8582 - recall_m: 0.8582 - val_loss: 0.4433 - val_acc: 0.8150 - val_f1_m: 0.8152 - val_precision_m: 0.8152 - val_recall_m: 0.8152\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3068 - acc: 0.8732 - f1_m: 0.8684 - precision_m: 0.8684 - recall_m: 0.8684 - val_loss: 0.4548 - val_acc: 0.8150 - val_f1_m: 0.8152 - val_precision_m: 0.8152 - val_recall_m: 0.8152\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3136 - acc: 0.8691 - f1_m: 0.8702 - precision_m: 0.8702 - recall_m: 0.8702 - val_loss: 0.4522 - val_acc: 0.8136 - val_f1_m: 0.8139 - val_precision_m: 0.8139 - val_recall_m: 0.8139\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2972 - acc: 0.8762 - f1_m: 0.8773 - precision_m: 0.8773 - recall_m: 0.8773 - val_loss: 0.4617 - val_acc: 0.8058 - val_f1_m: 0.8059 - val_precision_m: 0.8059 - val_recall_m: 0.8059\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6232 - acc: 0.7346 - f1_m: 0.7340 - precision_m: 0.7340 - recall_m: 0.7340 - val_loss: 0.4668 - val_acc: 0.8150 - val_f1_m: 0.8149 - val_precision_m: 0.8149 - val_recall_m: 0.8149\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4825 - acc: 0.7873 - f1_m: 0.7892 - precision_m: 0.7892 - recall_m: 0.7892 - val_loss: 0.4466 - val_acc: 0.8228 - val_f1_m: 0.8227 - val_precision_m: 0.8227 - val_recall_m: 0.8227\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4509 - acc: 0.8013 - f1_m: 0.8031 - precision_m: 0.8031 - recall_m: 0.8031 - val_loss: 0.4384 - val_acc: 0.8136 - val_f1_m: 0.8135 - val_precision_m: 0.8135 - val_recall_m: 0.8135\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4215 - acc: 0.8117 - f1_m: 0.8104 - precision_m: 0.8104 - recall_m: 0.8104 - val_loss: 0.4245 - val_acc: 0.8268 - val_f1_m: 0.8265 - val_precision_m: 0.8265 - val_recall_m: 0.8265\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4111 - acc: 0.8187 - f1_m: 0.8203 - precision_m: 0.8203 - recall_m: 0.8203 - val_loss: 0.4236 - val_acc: 0.8281 - val_f1_m: 0.8278 - val_precision_m: 0.8278 - val_recall_m: 0.8278\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3849 - acc: 0.8313 - f1_m: 0.8298 - precision_m: 0.8298 - recall_m: 0.8298 - val_loss: 0.4257 - val_acc: 0.8307 - val_f1_m: 0.8305 - val_precision_m: 0.8305 - val_recall_m: 0.8305\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3731 - acc: 0.8377 - f1_m: 0.8391 - precision_m: 0.8391 - recall_m: 0.8391 - val_loss: 0.4383 - val_acc: 0.8320 - val_f1_m: 0.8320 - val_precision_m: 0.8320 - val_recall_m: 0.8320\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3703 - acc: 0.8330 - f1_m: 0.8345 - precision_m: 0.8345 - recall_m: 0.8345 - val_loss: 0.4397 - val_acc: 0.8307 - val_f1_m: 0.8305 - val_precision_m: 0.8305 - val_recall_m: 0.8305\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3598 - acc: 0.8454 - f1_m: 0.8468 - precision_m: 0.8468 - recall_m: 0.8468 - val_loss: 0.4390 - val_acc: 0.8307 - val_f1_m: 0.8308 - val_precision_m: 0.8308 - val_recall_m: 0.8308\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3493 - acc: 0.8470 - f1_m: 0.8454 - precision_m: 0.8454 - recall_m: 0.8454 - val_loss: 0.4362 - val_acc: 0.8320 - val_f1_m: 0.8321 - val_precision_m: 0.8321 - val_recall_m: 0.8321\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3426 - acc: 0.8527 - f1_m: 0.8481 - precision_m: 0.8481 - recall_m: 0.8481 - val_loss: 0.4412 - val_acc: 0.8268 - val_f1_m: 0.8269 - val_precision_m: 0.8269 - val_recall_m: 0.8269\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3322 - acc: 0.8562 - f1_m: 0.8516 - precision_m: 0.8516 - recall_m: 0.8516 - val_loss: 0.4440 - val_acc: 0.8268 - val_f1_m: 0.8265 - val_precision_m: 0.8265 - val_recall_m: 0.8265\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3234 - acc: 0.8659 - f1_m: 0.8641 - precision_m: 0.8641 - recall_m: 0.8641 - val_loss: 0.4459 - val_acc: 0.8241 - val_f1_m: 0.8242 - val_precision_m: 0.8242 - val_recall_m: 0.8242\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3144 - acc: 0.8656 - f1_m: 0.8609 - precision_m: 0.8609 - recall_m: 0.8609 - val_loss: 0.4725 - val_acc: 0.8281 - val_f1_m: 0.8279 - val_precision_m: 0.8279 - val_recall_m: 0.8279\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3038 - acc: 0.8683 - f1_m: 0.8666 - precision_m: 0.8666 - recall_m: 0.8666 - val_loss: 0.4531 - val_acc: 0.8320 - val_f1_m: 0.8321 - val_precision_m: 0.8321 - val_recall_m: 0.8321\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3036 - acc: 0.8708 - f1_m: 0.8720 - precision_m: 0.8720 - recall_m: 0.8720 - val_loss: 0.4815 - val_acc: 0.8136 - val_f1_m: 0.8136 - val_precision_m: 0.8136 - val_recall_m: 0.8136\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2834 - acc: 0.8778 - f1_m: 0.8789 - precision_m: 0.8789 - recall_m: 0.8789 - val_loss: 0.4882 - val_acc: 0.8281 - val_f1_m: 0.8279 - val_precision_m: 0.8279 - val_recall_m: 0.8279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2741 - acc: 0.8867 - f1_m: 0.8848 - precision_m: 0.8848 - recall_m: 0.8848 - val_loss: 0.4774 - val_acc: 0.8215 - val_f1_m: 0.8214 - val_precision_m: 0.8214 - val_recall_m: 0.8214\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2640 - acc: 0.8856 - f1_m: 0.8836 - precision_m: 0.8836 - recall_m: 0.8836 - val_loss: 0.5057 - val_acc: 0.8150 - val_f1_m: 0.8149 - val_precision_m: 0.8149 - val_recall_m: 0.8149\n",
      "Epoch 20/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2659 - acc: 0.8915 - f1_m: 0.8925 - precision_m: 0.8925 - recall_m: 0.8925 - val_loss: 0.5197 - val_acc: 0.8189 - val_f1_m: 0.8190 - val_precision_m: 0.8190 - val_recall_m: 0.8190\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6081 - acc: 0.7418 - f1_m: 0.7441 - precision_m: 0.7441 - recall_m: 0.7441 - val_loss: 0.4906 - val_acc: 0.7966 - val_f1_m: 0.7966 - val_precision_m: 0.7966 - val_recall_m: 0.7966\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4818 - acc: 0.7865 - f1_m: 0.7825 - precision_m: 0.7825 - recall_m: 0.7825 - val_loss: 0.4534 - val_acc: 0.8058 - val_f1_m: 0.8059 - val_precision_m: 0.8059 - val_recall_m: 0.8059\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4449 - acc: 0.8067 - f1_m: 0.8026 - precision_m: 0.8026 - recall_m: 0.8026 - val_loss: 0.4402 - val_acc: 0.8084 - val_f1_m: 0.8088 - val_precision_m: 0.8088 - val_recall_m: 0.8088\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4128 - acc: 0.8190 - f1_m: 0.8206 - precision_m: 0.8206 - recall_m: 0.8206 - val_loss: 0.4425 - val_acc: 0.8163 - val_f1_m: 0.8165 - val_precision_m: 0.8165 - val_recall_m: 0.8165\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4018 - acc: 0.8267 - f1_m: 0.8253 - precision_m: 0.8253 - recall_m: 0.8253 - val_loss: 0.4492 - val_acc: 0.8084 - val_f1_m: 0.8087 - val_precision_m: 0.8087 - val_recall_m: 0.8087\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3883 - acc: 0.8345 - f1_m: 0.8330 - precision_m: 0.8330 - recall_m: 0.8330 - val_loss: 0.4441 - val_acc: 0.8018 - val_f1_m: 0.8022 - val_precision_m: 0.8022 - val_recall_m: 0.8022\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3807 - acc: 0.8346 - f1_m: 0.8361 - precision_m: 0.8361 - recall_m: 0.8361 - val_loss: 0.4551 - val_acc: 0.8031 - val_f1_m: 0.8036 - val_precision_m: 0.8036 - val_recall_m: 0.8036\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8431 - f1_m: 0.8415 - precision_m: 0.8415 - recall_m: 0.8415 - val_loss: 0.4595 - val_acc: 0.8163 - val_f1_m: 0.8166 - val_precision_m: 0.8166 - val_recall_m: 0.8166\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3642 - acc: 0.8418 - f1_m: 0.8402 - precision_m: 0.8402 - recall_m: 0.8402 - val_loss: 0.4570 - val_acc: 0.8123 - val_f1_m: 0.8127 - val_precision_m: 0.8127 - val_recall_m: 0.8127\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3471 - acc: 0.8524 - f1_m: 0.8537 - precision_m: 0.8537 - recall_m: 0.8537 - val_loss: 0.4622 - val_acc: 0.8163 - val_f1_m: 0.8166 - val_precision_m: 0.8166 - val_recall_m: 0.8166\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3279 - acc: 0.8637 - f1_m: 0.8619 - precision_m: 0.8619 - recall_m: 0.8619 - val_loss: 0.4873 - val_acc: 0.8045 - val_f1_m: 0.8048 - val_precision_m: 0.8048 - val_recall_m: 0.8048\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3337 - acc: 0.8575 - f1_m: 0.8588 - precision_m: 0.8588 - recall_m: 0.8588 - val_loss: 0.4832 - val_acc: 0.7940 - val_f1_m: 0.7945 - val_precision_m: 0.7945 - val_recall_m: 0.7945\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3140 - acc: 0.8675 - f1_m: 0.8657 - precision_m: 0.8657 - recall_m: 0.8657 - val_loss: 0.4887 - val_acc: 0.8018 - val_f1_m: 0.8023 - val_precision_m: 0.8023 - val_recall_m: 0.8023\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3177 - acc: 0.8691 - f1_m: 0.8702 - precision_m: 0.8702 - recall_m: 0.8702 - val_loss: 0.5102 - val_acc: 0.7848 - val_f1_m: 0.7854 - val_precision_m: 0.7854 - val_recall_m: 0.7854\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3058 - acc: 0.8653 - f1_m: 0.8635 - precision_m: 0.8635 - recall_m: 0.8635 - val_loss: 0.5144 - val_acc: 0.8031 - val_f1_m: 0.8036 - val_precision_m: 0.8036 - val_recall_m: 0.8036\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2968 - acc: 0.8761 - f1_m: 0.8772 - precision_m: 0.8772 - recall_m: 0.8772 - val_loss: 0.5241 - val_acc: 0.8031 - val_f1_m: 0.8037 - val_precision_m: 0.8037 - val_recall_m: 0.8037\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2875 - acc: 0.8786 - f1_m: 0.8796 - precision_m: 0.8796 - recall_m: 0.8796 - val_loss: 0.5449 - val_acc: 0.7913 - val_f1_m: 0.7919 - val_precision_m: 0.7919 - val_recall_m: 0.7919\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2753 - acc: 0.8841 - f1_m: 0.8792 - precision_m: 0.8792 - recall_m: 0.8792 - val_loss: 0.5482 - val_acc: 0.7756 - val_f1_m: 0.7761 - val_precision_m: 0.7761 - val_recall_m: 0.7761\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6171 - acc: 0.7306 - f1_m: 0.7286 - precision_m: 0.7286 - recall_m: 0.7286 - val_loss: 0.4822 - val_acc: 0.7871 - val_f1_m: 0.7878 - val_precision_m: 0.7878 - val_recall_m: 0.7878\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4717 - acc: 0.7903 - f1_m: 0.7899 - precision_m: 0.7899 - recall_m: 0.7899 - val_loss: 0.4696 - val_acc: 0.7911 - val_f1_m: 0.7914 - val_precision_m: 0.7914 - val_recall_m: 0.7914\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4451 - acc: 0.8053 - f1_m: 0.8048 - precision_m: 0.8048 - recall_m: 0.8048 - val_loss: 0.4697 - val_acc: 0.7819 - val_f1_m: 0.7821 - val_precision_m: 0.7821 - val_recall_m: 0.7821\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4180 - acc: 0.8184 - f1_m: 0.8157 - precision_m: 0.8157 - recall_m: 0.8157 - val_loss: 0.4623 - val_acc: 0.7871 - val_f1_m: 0.7871 - val_precision_m: 0.7871 - val_recall_m: 0.7871\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4055 - acc: 0.8247 - f1_m: 0.8219 - precision_m: 0.8219 - recall_m: 0.8219 - val_loss: 0.4686 - val_acc: 0.7858 - val_f1_m: 0.7857 - val_precision_m: 0.7857 - val_recall_m: 0.7857\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3924 - acc: 0.8310 - f1_m: 0.8325 - precision_m: 0.8325 - recall_m: 0.8325 - val_loss: 0.4693 - val_acc: 0.7911 - val_f1_m: 0.7914 - val_precision_m: 0.7914 - val_recall_m: 0.7914\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3791 - acc: 0.8371 - f1_m: 0.8385 - precision_m: 0.8385 - recall_m: 0.8385 - val_loss: 0.4607 - val_acc: 0.7898 - val_f1_m: 0.7897 - val_precision_m: 0.7897 - val_recall_m: 0.7897\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3712 - acc: 0.8358 - f1_m: 0.8372 - precision_m: 0.8372 - recall_m: 0.8372 - val_loss: 0.4697 - val_acc: 0.8016 - val_f1_m: 0.8016 - val_precision_m: 0.8016 - val_recall_m: 0.8016\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3645 - acc: 0.8411 - f1_m: 0.8403 - precision_m: 0.8403 - recall_m: 0.8403 - val_loss: 0.4693 - val_acc: 0.7898 - val_f1_m: 0.7902 - val_precision_m: 0.7902 - val_recall_m: 0.7902\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.8527 - f1_m: 0.8497 - precision_m: 0.8497 - recall_m: 0.8497 - val_loss: 0.4855 - val_acc: 0.7871 - val_f1_m: 0.7876 - val_precision_m: 0.7876 - val_recall_m: 0.7876\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3457 - acc: 0.8562 - f1_m: 0.8553 - precision_m: 0.8553 - recall_m: 0.8553 - val_loss: 0.5068 - val_acc: 0.7924 - val_f1_m: 0.7924 - val_precision_m: 0.7924 - val_recall_m: 0.7924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8574 - f1_m: 0.8565 - precision_m: 0.8565 - recall_m: 0.8565 - val_loss: 0.5108 - val_acc: 0.7937 - val_f1_m: 0.7935 - val_precision_m: 0.7935 - val_recall_m: 0.7935\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3235 - acc: 0.8614 - f1_m: 0.8626 - precision_m: 0.8626 - recall_m: 0.8626 - val_loss: 0.5082 - val_acc: 0.7871 - val_f1_m: 0.7873 - val_precision_m: 0.7873 - val_recall_m: 0.7873\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3149 - acc: 0.8660 - f1_m: 0.8650 - precision_m: 0.8650 - recall_m: 0.8650 - val_loss: 0.5223 - val_acc: 0.7766 - val_f1_m: 0.7767 - val_precision_m: 0.7767 - val_recall_m: 0.7767\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3130 - acc: 0.8651 - f1_m: 0.8663 - precision_m: 0.8663 - recall_m: 0.8663 - val_loss: 0.5128 - val_acc: 0.7950 - val_f1_m: 0.7948 - val_precision_m: 0.7948 - val_recall_m: 0.7948\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2976 - acc: 0.8714 - f1_m: 0.8725 - precision_m: 0.8725 - recall_m: 0.8725 - val_loss: 0.5010 - val_acc: 0.7871 - val_f1_m: 0.7871 - val_precision_m: 0.7871 - val_recall_m: 0.7871\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2819 - acc: 0.8827 - f1_m: 0.8815 - precision_m: 0.8815 - recall_m: 0.8815 - val_loss: 0.5169 - val_acc: 0.7832 - val_f1_m: 0.7834 - val_precision_m: 0.7834 - val_recall_m: 0.7834\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2828 - acc: 0.8816 - f1_m: 0.8805 - precision_m: 0.8805 - recall_m: 0.8805 - val_loss: 0.5658 - val_acc: 0.7753 - val_f1_m: 0.7751 - val_precision_m: 0.7751 - val_recall_m: 0.7751\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6191 - acc: 0.7303 - f1_m: 0.7240 - precision_m: 0.7240 - recall_m: 0.7240 - val_loss: 0.4281 - val_acc: 0.8200 - val_f1_m: 0.8199 - val_precision_m: 0.8199 - val_recall_m: 0.8199\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4926 - acc: 0.7853 - f1_m: 0.7850 - precision_m: 0.7850 - recall_m: 0.7850 - val_loss: 0.4213 - val_acc: 0.8239 - val_f1_m: 0.8234 - val_precision_m: 0.8234 - val_recall_m: 0.8234\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4402 - acc: 0.8065 - f1_m: 0.8060 - precision_m: 0.8060 - recall_m: 0.8060 - val_loss: 0.4107 - val_acc: 0.8239 - val_f1_m: 0.8234 - val_precision_m: 0.8234 - val_recall_m: 0.8234\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4190 - acc: 0.8173 - f1_m: 0.8189 - precision_m: 0.8189 - recall_m: 0.8189 - val_loss: 0.4107 - val_acc: 0.8213 - val_f1_m: 0.8213 - val_precision_m: 0.8213 - val_recall_m: 0.8213\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4080 - acc: 0.8230 - f1_m: 0.8202 - precision_m: 0.8202 - recall_m: 0.8202 - val_loss: 0.4072 - val_acc: 0.8226 - val_f1_m: 0.8225 - val_precision_m: 0.8225 - val_recall_m: 0.8225\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3896 - acc: 0.8307 - f1_m: 0.8322 - precision_m: 0.8322 - recall_m: 0.8322 - val_loss: 0.4155 - val_acc: 0.8173 - val_f1_m: 0.8171 - val_precision_m: 0.8171 - val_recall_m: 0.8171\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3825 - acc: 0.8320 - f1_m: 0.8335 - precision_m: 0.8335 - recall_m: 0.8335 - val_loss: 0.4141 - val_acc: 0.8121 - val_f1_m: 0.8120 - val_precision_m: 0.8120 - val_recall_m: 0.8120\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3757 - acc: 0.8348 - f1_m: 0.8341 - precision_m: 0.8341 - recall_m: 0.8341 - val_loss: 0.4050 - val_acc: 0.8265 - val_f1_m: 0.8267 - val_precision_m: 0.8267 - val_recall_m: 0.8267\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3600 - acc: 0.8444 - f1_m: 0.8458 - precision_m: 0.8458 - recall_m: 0.8458 - val_loss: 0.4115 - val_acc: 0.8213 - val_f1_m: 0.8213 - val_precision_m: 0.8213 - val_recall_m: 0.8213\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3552 - acc: 0.8462 - f1_m: 0.8432 - precision_m: 0.8432 - recall_m: 0.8432 - val_loss: 0.4174 - val_acc: 0.8239 - val_f1_m: 0.8236 - val_precision_m: 0.8236 - val_recall_m: 0.8236\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3398 - acc: 0.8532 - f1_m: 0.8523 - precision_m: 0.8523 - recall_m: 0.8523 - val_loss: 0.4149 - val_acc: 0.8252 - val_f1_m: 0.8249 - val_precision_m: 0.8249 - val_recall_m: 0.8249\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3383 - acc: 0.8538 - f1_m: 0.8529 - precision_m: 0.8529 - recall_m: 0.8529 - val_loss: 0.4228 - val_acc: 0.8292 - val_f1_m: 0.8293 - val_precision_m: 0.8293 - val_recall_m: 0.8293\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3297 - acc: 0.8586 - f1_m: 0.8576 - precision_m: 0.8576 - recall_m: 0.8576 - val_loss: 0.4269 - val_acc: 0.8226 - val_f1_m: 0.8228 - val_precision_m: 0.8228 - val_recall_m: 0.8228\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3218 - acc: 0.8635 - f1_m: 0.8647 - precision_m: 0.8647 - recall_m: 0.8647 - val_loss: 0.4333 - val_acc: 0.8213 - val_f1_m: 0.8215 - val_precision_m: 0.8215 - val_recall_m: 0.8215\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3051 - acc: 0.8705 - f1_m: 0.8673 - precision_m: 0.8673 - recall_m: 0.8673 - val_loss: 0.4489 - val_acc: 0.8147 - val_f1_m: 0.8148 - val_precision_m: 0.8148 - val_recall_m: 0.8148\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3034 - acc: 0.8723 - f1_m: 0.8669 - precision_m: 0.8669 - recall_m: 0.8669 - val_loss: 0.4435 - val_acc: 0.8239 - val_f1_m: 0.8239 - val_precision_m: 0.8239 - val_recall_m: 0.8239\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2871 - acc: 0.8793 - f1_m: 0.8804 - precision_m: 0.8804 - recall_m: 0.8804 - val_loss: 0.4576 - val_acc: 0.8213 - val_f1_m: 0.8215 - val_precision_m: 0.8215 - val_recall_m: 0.8215\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2906 - acc: 0.8762 - f1_m: 0.8773 - precision_m: 0.8773 - recall_m: 0.8773 - val_loss: 0.4565 - val_acc: 0.8187 - val_f1_m: 0.8184 - val_precision_m: 0.8184 - val_recall_m: 0.8184\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2717 - acc: 0.8865 - f1_m: 0.8831 - precision_m: 0.8831 - recall_m: 0.8831 - val_loss: 0.4722 - val_acc: 0.8121 - val_f1_m: 0.8117 - val_precision_m: 0.8117 - val_recall_m: 0.8117\n",
      "Epoch 20/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.8920 - f1_m: 0.8864 - precision_m: 0.8864 - recall_m: 0.8864 - val_loss: 0.4792 - val_acc: 0.8068 - val_f1_m: 0.8065 - val_precision_m: 0.8065 - val_recall_m: 0.8065\n",
      "Epoch 21/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2744 - acc: 0.8869 - f1_m: 0.8879 - precision_m: 0.8879 - recall_m: 0.8879 - val_loss: 0.4742 - val_acc: 0.8239 - val_f1_m: 0.8238 - val_precision_m: 0.8238 - val_recall_m: 0.8238\n",
      "Epoch 22/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.8920 - f1_m: 0.8886 - precision_m: 0.8886 - recall_m: 0.8886 - val_loss: 0.5024 - val_acc: 0.8239 - val_f1_m: 0.8238 - val_precision_m: 0.8238 - val_recall_m: 0.8238\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6038 - acc: 0.7440 - f1_m: 0.7441 - precision_m: 0.7441 - recall_m: 0.7441 - val_loss: 0.4611 - val_acc: 0.7976 - val_f1_m: 0.7979 - val_precision_m: 0.7979 - val_recall_m: 0.7979\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4835 - acc: 0.7856 - f1_m: 0.7875 - precision_m: 0.7875 - recall_m: 0.7875 - val_loss: 0.4301 - val_acc: 0.7976 - val_f1_m: 0.7977 - val_precision_m: 0.7977 - val_recall_m: 0.7977\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4416 - acc: 0.8015 - f1_m: 0.7989 - precision_m: 0.7989 - recall_m: 0.7989 - val_loss: 0.4213 - val_acc: 0.8042 - val_f1_m: 0.8041 - val_precision_m: 0.8041 - val_recall_m: 0.8041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4165 - acc: 0.8179 - f1_m: 0.8173 - precision_m: 0.8173 - recall_m: 0.8173 - val_loss: 0.4348 - val_acc: 0.7976 - val_f1_m: 0.7977 - val_precision_m: 0.7977 - val_recall_m: 0.7977\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4053 - acc: 0.8219 - f1_m: 0.8235 - precision_m: 0.8235 - recall_m: 0.8235 - val_loss: 0.4216 - val_acc: 0.8055 - val_f1_m: 0.8055 - val_precision_m: 0.8055 - val_recall_m: 0.8055\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3834 - acc: 0.8317 - f1_m: 0.8332 - precision_m: 0.8332 - recall_m: 0.8332 - val_loss: 0.4244 - val_acc: 0.8081 - val_f1_m: 0.8080 - val_precision_m: 0.8080 - val_recall_m: 0.8080\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3812 - acc: 0.8309 - f1_m: 0.8323 - precision_m: 0.8323 - recall_m: 0.8323 - val_loss: 0.4291 - val_acc: 0.8095 - val_f1_m: 0.8091 - val_precision_m: 0.8091 - val_recall_m: 0.8091\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3722 - acc: 0.8387 - f1_m: 0.8401 - precision_m: 0.8401 - recall_m: 0.8401 - val_loss: 0.4259 - val_acc: 0.8095 - val_f1_m: 0.8094 - val_precision_m: 0.8094 - val_recall_m: 0.8094\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3570 - acc: 0.8479 - f1_m: 0.8471 - precision_m: 0.8471 - recall_m: 0.8471 - val_loss: 0.4277 - val_acc: 0.8134 - val_f1_m: 0.8135 - val_precision_m: 0.8135 - val_recall_m: 0.8135\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3455 - acc: 0.8465 - f1_m: 0.8456 - precision_m: 0.8456 - recall_m: 0.8456 - val_loss: 0.4361 - val_acc: 0.8108 - val_f1_m: 0.8104 - val_precision_m: 0.8104 - val_recall_m: 0.8104\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3428 - acc: 0.8557 - f1_m: 0.8569 - precision_m: 0.8569 - recall_m: 0.8569 - val_loss: 0.4469 - val_acc: 0.8029 - val_f1_m: 0.8028 - val_precision_m: 0.8028 - val_recall_m: 0.8028\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3251 - acc: 0.8596 - f1_m: 0.8608 - precision_m: 0.8608 - recall_m: 0.8608 - val_loss: 0.4579 - val_acc: 0.7937 - val_f1_m: 0.7937 - val_precision_m: 0.7937 - val_recall_m: 0.7937\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3177 - acc: 0.8625 - f1_m: 0.8615 - precision_m: 0.8615 - recall_m: 0.8615 - val_loss: 0.4528 - val_acc: 0.8029 - val_f1_m: 0.8029 - val_precision_m: 0.8029 - val_recall_m: 0.8029\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3144 - acc: 0.8633 - f1_m: 0.8601 - precision_m: 0.8601 - recall_m: 0.8601 - val_loss: 0.4594 - val_acc: 0.8042 - val_f1_m: 0.8041 - val_precision_m: 0.8041 - val_recall_m: 0.8041\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3076 - acc: 0.8681 - f1_m: 0.8692 - precision_m: 0.8692 - recall_m: 0.8692 - val_loss: 0.4666 - val_acc: 0.8081 - val_f1_m: 0.8080 - val_precision_m: 0.8080 - val_recall_m: 0.8080\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2895 - acc: 0.8774 - f1_m: 0.8763 - precision_m: 0.8763 - recall_m: 0.8763 - val_loss: 0.4856 - val_acc: 0.8108 - val_f1_m: 0.8107 - val_precision_m: 0.8107 - val_recall_m: 0.8107\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2826 - acc: 0.8815 - f1_m: 0.8782 - precision_m: 0.8782 - recall_m: 0.8782 - val_loss: 0.4815 - val_acc: 0.8095 - val_f1_m: 0.8094 - val_precision_m: 0.8094 - val_recall_m: 0.8094\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2751 - acc: 0.8834 - f1_m: 0.8822 - precision_m: 0.8822 - recall_m: 0.8822 - val_loss: 0.5086 - val_acc: 0.8042 - val_f1_m: 0.8038 - val_precision_m: 0.8038 - val_recall_m: 0.8038\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2693 - acc: 0.8917 - f1_m: 0.8927 - precision_m: 0.8927 - recall_m: 0.8927 - val_loss: 0.4854 - val_acc: 0.8016 - val_f1_m: 0.8013 - val_precision_m: 0.8013 - val_recall_m: 0.8013\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6257 - acc: 0.7332 - f1_m: 0.7355 - precision_m: 0.7355 - recall_m: 0.7355 - val_loss: 0.4596 - val_acc: 0.7819 - val_f1_m: 0.7815 - val_precision_m: 0.7815 - val_recall_m: 0.7815\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4934 - acc: 0.7872 - f1_m: 0.7826 - precision_m: 0.7826 - recall_m: 0.7826 - val_loss: 0.4499 - val_acc: 0.8003 - val_f1_m: 0.7994 - val_precision_m: 0.7994 - val_recall_m: 0.7994\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4330 - acc: 0.8095 - f1_m: 0.8069 - precision_m: 0.8069 - recall_m: 0.8069 - val_loss: 0.4310 - val_acc: 0.8213 - val_f1_m: 0.8204 - val_precision_m: 0.8204 - val_recall_m: 0.8204\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4233 - acc: 0.8094 - f1_m: 0.8089 - precision_m: 0.8089 - recall_m: 0.8089 - val_loss: 0.4278 - val_acc: 0.8200 - val_f1_m: 0.8189 - val_precision_m: 0.8189 - val_recall_m: 0.8189\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4057 - acc: 0.8259 - f1_m: 0.8231 - precision_m: 0.8231 - recall_m: 0.8231 - val_loss: 0.4312 - val_acc: 0.8095 - val_f1_m: 0.8086 - val_precision_m: 0.8086 - val_recall_m: 0.8086\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3964 - acc: 0.8255 - f1_m: 0.8248 - precision_m: 0.8248 - recall_m: 0.8248 - val_loss: 0.4299 - val_acc: 0.8068 - val_f1_m: 0.8059 - val_precision_m: 0.8059 - val_recall_m: 0.8059\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3821 - acc: 0.8316 - f1_m: 0.8265 - precision_m: 0.8265 - recall_m: 0.8265 - val_loss: 0.4274 - val_acc: 0.8147 - val_f1_m: 0.8137 - val_precision_m: 0.8137 - val_recall_m: 0.8137\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3775 - acc: 0.8319 - f1_m: 0.8290 - precision_m: 0.8290 - recall_m: 0.8290 - val_loss: 0.4276 - val_acc: 0.8081 - val_f1_m: 0.8073 - val_precision_m: 0.8073 - val_recall_m: 0.8073\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3674 - acc: 0.8418 - f1_m: 0.8410 - precision_m: 0.8410 - recall_m: 0.8410 - val_loss: 0.4274 - val_acc: 0.8279 - val_f1_m: 0.8270 - val_precision_m: 0.8270 - val_recall_m: 0.8270\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3520 - acc: 0.8469 - f1_m: 0.8482 - precision_m: 0.8482 - recall_m: 0.8482 - val_loss: 0.4271 - val_acc: 0.8081 - val_f1_m: 0.8073 - val_precision_m: 0.8073 - val_recall_m: 0.8073\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3480 - acc: 0.8489 - f1_m: 0.8437 - precision_m: 0.8438 - recall_m: 0.8438 - val_loss: 0.4275 - val_acc: 0.8134 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3285 - acc: 0.8587 - f1_m: 0.8600 - precision_m: 0.8600 - recall_m: 0.8600 - val_loss: 0.4371 - val_acc: 0.8095 - val_f1_m: 0.8083 - val_precision_m: 0.8083 - val_recall_m: 0.8083\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3249 - acc: 0.8627 - f1_m: 0.8617 - precision_m: 0.8617 - recall_m: 0.8617 - val_loss: 0.4384 - val_acc: 0.8029 - val_f1_m: 0.8023 - val_precision_m: 0.8023 - val_recall_m: 0.8023\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3176 - acc: 0.8595 - f1_m: 0.8585 - precision_m: 0.8585 - recall_m: 0.8585 - val_loss: 0.4619 - val_acc: 0.8029 - val_f1_m: 0.8018 - val_precision_m: 0.8018 - val_recall_m: 0.8018\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3106 - acc: 0.8707 - f1_m: 0.8718 - precision_m: 0.8718 - recall_m: 0.8718 - val_loss: 0.4556 - val_acc: 0.8055 - val_f1_m: 0.8044 - val_precision_m: 0.8044 - val_recall_m: 0.8044\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2901 - acc: 0.8789 - f1_m: 0.8799 - precision_m: 0.8799 - recall_m: 0.8799 - val_loss: 0.4547 - val_acc: 0.8121 - val_f1_m: 0.8109 - val_precision_m: 0.8109 - val_recall_m: 0.8109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2816 - acc: 0.8805 - f1_m: 0.8815 - precision_m: 0.8815 - recall_m: 0.8815 - val_loss: 0.4874 - val_acc: 0.8121 - val_f1_m: 0.8112 - val_precision_m: 0.8112 - val_recall_m: 0.8112\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2818 - acc: 0.8800 - f1_m: 0.8789 - precision_m: 0.8789 - recall_m: 0.8789 - val_loss: 0.4723 - val_acc: 0.8029 - val_f1_m: 0.8016 - val_precision_m: 0.8016 - val_recall_m: 0.8016\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2807 - acc: 0.8813 - f1_m: 0.8780 - precision_m: 0.8780 - recall_m: 0.8780 - val_loss: 0.4699 - val_acc: 0.8029 - val_f1_m: 0.8015 - val_precision_m: 0.8015 - val_recall_m: 0.8015\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.5978 - acc: 0.7395 - f1_m: 0.7396 - precision_m: 0.7396 - recall_m: 0.7396 - val_loss: 0.4899 - val_acc: 0.7898 - val_f1_m: 0.7904 - val_precision_m: 0.7904 - val_recall_m: 0.7904\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4765 - acc: 0.7913 - f1_m: 0.7931 - precision_m: 0.7931 - recall_m: 0.7931 - val_loss: 0.4671 - val_acc: 0.7963 - val_f1_m: 0.7971 - val_precision_m: 0.7971 - val_recall_m: 0.7971\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4393 - acc: 0.8076 - f1_m: 0.8093 - precision_m: 0.8093 - recall_m: 0.8093 - val_loss: 0.4494 - val_acc: 0.7937 - val_f1_m: 0.7948 - val_precision_m: 0.7948 - val_recall_m: 0.7948\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4117 - acc: 0.8228 - f1_m: 0.8244 - precision_m: 0.8244 - recall_m: 0.8244 - val_loss: 0.4589 - val_acc: 0.7989 - val_f1_m: 0.7995 - val_precision_m: 0.7995 - val_recall_m: 0.7995\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3946 - acc: 0.8301 - f1_m: 0.8316 - precision_m: 0.8316 - recall_m: 0.8316 - val_loss: 0.4523 - val_acc: 0.7911 - val_f1_m: 0.7922 - val_precision_m: 0.7922 - val_recall_m: 0.7922\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3861 - acc: 0.8291 - f1_m: 0.8306 - precision_m: 0.8306 - recall_m: 0.8306 - val_loss: 0.4605 - val_acc: 0.7924 - val_f1_m: 0.7933 - val_precision_m: 0.7933 - val_recall_m: 0.7933\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3735 - acc: 0.8399 - f1_m: 0.8370 - precision_m: 0.8370 - recall_m: 0.8370 - val_loss: 0.4707 - val_acc: 0.7792 - val_f1_m: 0.7803 - val_precision_m: 0.7803 - val_recall_m: 0.7803\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3622 - acc: 0.8408 - f1_m: 0.8422 - precision_m: 0.8422 - recall_m: 0.8422 - val_loss: 0.4760 - val_acc: 0.7792 - val_f1_m: 0.7805 - val_precision_m: 0.7805 - val_recall_m: 0.7805\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3491 - acc: 0.8489 - f1_m: 0.8481 - precision_m: 0.8481 - recall_m: 0.8481 - val_loss: 0.4901 - val_acc: 0.7740 - val_f1_m: 0.7754 - val_precision_m: 0.7754 - val_recall_m: 0.7754\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.8543 - f1_m: 0.8534 - precision_m: 0.8534 - recall_m: 0.8534 - val_loss: 0.4979 - val_acc: 0.7871 - val_f1_m: 0.7884 - val_precision_m: 0.7884 - val_recall_m: 0.7884\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3363 - acc: 0.8542 - f1_m: 0.8533 - precision_m: 0.8533 - recall_m: 0.8533 - val_loss: 0.5046 - val_acc: 0.7753 - val_f1_m: 0.7764 - val_precision_m: 0.7764 - val_recall_m: 0.7764\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3250 - acc: 0.8608 - f1_m: 0.8620 - precision_m: 0.8620 - recall_m: 0.8620 - val_loss: 0.5046 - val_acc: 0.7779 - val_f1_m: 0.7788 - val_precision_m: 0.7788 - val_recall_m: 0.7788\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3103 - acc: 0.8710 - f1_m: 0.8721 - precision_m: 0.8721 - recall_m: 0.8721 - val_loss: 0.5132 - val_acc: 0.7779 - val_f1_m: 0.7791 - val_precision_m: 0.7791 - val_recall_m: 0.7791\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2965 - acc: 0.8773 - f1_m: 0.8762 - precision_m: 0.8762 - recall_m: 0.8762 - val_loss: 0.5635 - val_acc: 0.7740 - val_f1_m: 0.7746 - val_precision_m: 0.7746 - val_recall_m: 0.7746\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6140 - acc: 0.7398 - f1_m: 0.7377 - precision_m: 0.7377 - recall_m: 0.7377 - val_loss: 0.4350 - val_acc: 0.8081 - val_f1_m: 0.8083 - val_precision_m: 0.8083 - val_recall_m: 0.8083\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4827 - acc: 0.7884 - f1_m: 0.7837 - precision_m: 0.7837 - recall_m: 0.7837 - val_loss: 0.4115 - val_acc: 0.8200 - val_f1_m: 0.8200 - val_precision_m: 0.8200 - val_recall_m: 0.8200\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4416 - acc: 0.8021 - f1_m: 0.7995 - precision_m: 0.7995 - recall_m: 0.7995 - val_loss: 0.4053 - val_acc: 0.8331 - val_f1_m: 0.8332 - val_precision_m: 0.8332 - val_recall_m: 0.8332\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4136 - acc: 0.8228 - f1_m: 0.8222 - precision_m: 0.8222 - recall_m: 0.8222 - val_loss: 0.4070 - val_acc: 0.8279 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4070 - acc: 0.8241 - f1_m: 0.8257 - precision_m: 0.8257 - recall_m: 0.8257 - val_loss: 0.4028 - val_acc: 0.8200 - val_f1_m: 0.8202 - val_precision_m: 0.8202 - val_recall_m: 0.8202\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3910 - acc: 0.8266 - f1_m: 0.8238 - precision_m: 0.8238 - recall_m: 0.8238 - val_loss: 0.4025 - val_acc: 0.8318 - val_f1_m: 0.8322 - val_precision_m: 0.8322 - val_recall_m: 0.8322\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3851 - acc: 0.8339 - f1_m: 0.8332 - precision_m: 0.8332 - recall_m: 0.8332 - val_loss: 0.4072 - val_acc: 0.8265 - val_f1_m: 0.8267 - val_precision_m: 0.8267 - val_recall_m: 0.8267\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3693 - acc: 0.8399 - f1_m: 0.8370 - precision_m: 0.8370 - recall_m: 0.8370 - val_loss: 0.4197 - val_acc: 0.8279 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3639 - acc: 0.8414 - f1_m: 0.8362 - precision_m: 0.8362 - recall_m: 0.8362 - val_loss: 0.4063 - val_acc: 0.8292 - val_f1_m: 0.8294 - val_precision_m: 0.8294 - val_recall_m: 0.8294\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3580 - acc: 0.8447 - f1_m: 0.8417 - precision_m: 0.8417 - recall_m: 0.8417 - val_loss: 0.4048 - val_acc: 0.8239 - val_f1_m: 0.8241 - val_precision_m: 0.8241 - val_recall_m: 0.8241\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8495 - f1_m: 0.8487 - precision_m: 0.8487 - recall_m: 0.8487 - val_loss: 0.4352 - val_acc: 0.8108 - val_f1_m: 0.8109 - val_precision_m: 0.8109 - val_recall_m: 0.8109\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3377 - acc: 0.8589 - f1_m: 0.8579 - precision_m: 0.8579 - recall_m: 0.8579 - val_loss: 0.4280 - val_acc: 0.8187 - val_f1_m: 0.8186 - val_precision_m: 0.8186 - val_recall_m: 0.8186\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.8583 - f1_m: 0.8595 - precision_m: 0.8595 - recall_m: 0.8595 - val_loss: 0.4399 - val_acc: 0.8187 - val_f1_m: 0.8186 - val_precision_m: 0.8186 - val_recall_m: 0.8186\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6100 - acc: 0.7389 - f1_m: 0.7390 - precision_m: 0.7390 - recall_m: 0.7390WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.6100 - acc: 0.7389 - f1_m: 0.7390 - precision_m: 0.7390 - recall_m: 0.7390 - val_loss: 0.4332 - val_acc: 0.8003 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4880 - acc: 0.7872 - f1_m: 0.7869 - precision_m: 0.7869 - recall_m: 0.7869 - val_loss: 0.4190 - val_acc: 0.8213 - val_f1_m: 0.8208 - val_precision_m: 0.8208 - val_recall_m: 0.8208\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4366 - acc: 0.8025 - f1_m: 0.7999 - precision_m: 0.7999 - recall_m: 0.7999 - val_loss: 0.4159 - val_acc: 0.8305 - val_f1_m: 0.8300 - val_precision_m: 0.8300 - val_recall_m: 0.8300\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4132 - acc: 0.8186 - f1_m: 0.8180 - precision_m: 0.8180 - recall_m: 0.8180 - val_loss: 0.4193 - val_acc: 0.8305 - val_f1_m: 0.8301 - val_precision_m: 0.8301 - val_recall_m: 0.8301\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4078 - acc: 0.8201 - f1_m: 0.8216 - precision_m: 0.8216 - recall_m: 0.8216 - val_loss: 0.4140 - val_acc: 0.8292 - val_f1_m: 0.8288 - val_precision_m: 0.8288 - val_recall_m: 0.8288\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3943 - acc: 0.8269 - f1_m: 0.8284 - precision_m: 0.8284 - recall_m: 0.8284 - val_loss: 0.4267 - val_acc: 0.8187 - val_f1_m: 0.8181 - val_precision_m: 0.8181 - val_recall_m: 0.8181\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3814 - acc: 0.8300 - f1_m: 0.8271 - precision_m: 0.8271 - recall_m: 0.8271 - val_loss: 0.4125 - val_acc: 0.8252 - val_f1_m: 0.8246 - val_precision_m: 0.8246 - val_recall_m: 0.8246\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3725 - acc: 0.8342 - f1_m: 0.8335 - precision_m: 0.8335 - recall_m: 0.8335 - val_loss: 0.4143 - val_acc: 0.8305 - val_f1_m: 0.8301 - val_precision_m: 0.8301 - val_recall_m: 0.8301\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3707 - acc: 0.8405 - f1_m: 0.8397 - precision_m: 0.8397 - recall_m: 0.8397 - val_loss: 0.4123 - val_acc: 0.8318 - val_f1_m: 0.8314 - val_precision_m: 0.8314 - val_recall_m: 0.8314\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3507 - acc: 0.8498 - f1_m: 0.8490 - precision_m: 0.8490 - recall_m: 0.8490 - val_loss: 0.4296 - val_acc: 0.8173 - val_f1_m: 0.8169 - val_precision_m: 0.8169 - val_recall_m: 0.8169\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3445 - acc: 0.8562 - f1_m: 0.8553 - precision_m: 0.8553 - recall_m: 0.8553 - val_loss: 0.4200 - val_acc: 0.8292 - val_f1_m: 0.8287 - val_precision_m: 0.8287 - val_recall_m: 0.8287\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3367 - acc: 0.8576 - f1_m: 0.8566 - precision_m: 0.8566 - recall_m: 0.8566 - val_loss: 0.4257 - val_acc: 0.8239 - val_f1_m: 0.8234 - val_precision_m: 0.8234 - val_recall_m: 0.8234\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3268 - acc: 0.8600 - f1_m: 0.8569 - precision_m: 0.8569 - recall_m: 0.8569 - val_loss: 0.4457 - val_acc: 0.8187 - val_f1_m: 0.8182 - val_precision_m: 0.8182 - val_recall_m: 0.8182\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3219 - acc: 0.8605 - f1_m: 0.8617 - precision_m: 0.8617 - recall_m: 0.8617 - val_loss: 0.4314 - val_acc: 0.8147 - val_f1_m: 0.8143 - val_precision_m: 0.8143 - val_recall_m: 0.8143\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3053 - acc: 0.8681 - f1_m: 0.8692 - precision_m: 0.8692 - recall_m: 0.8692 - val_loss: 0.4585 - val_acc: 0.8226 - val_f1_m: 0.8221 - val_precision_m: 0.8221 - val_recall_m: 0.8221\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2907 - acc: 0.8789 - f1_m: 0.8777 - precision_m: 0.8777 - recall_m: 0.8777 - val_loss: 0.4554 - val_acc: 0.8292 - val_f1_m: 0.8287 - val_precision_m: 0.8287 - val_recall_m: 0.8287\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2806 - acc: 0.8803 - f1_m: 0.8814 - precision_m: 0.8814 - recall_m: 0.8814 - val_loss: 0.4713 - val_acc: 0.8187 - val_f1_m: 0.8182 - val_precision_m: 0.8182 - val_recall_m: 0.8182\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2824 - acc: 0.8796 - f1_m: 0.8785 - precision_m: 0.8785 - recall_m: 0.8785 - val_loss: 0.4585 - val_acc: 0.8252 - val_f1_m: 0.8247 - val_precision_m: 0.8247 - val_recall_m: 0.8247\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2761 - acc: 0.8824 - f1_m: 0.8791 - precision_m: 0.8791 - recall_m: 0.8791 - val_loss: 0.4823 - val_acc: 0.8003 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# I followed this guide to get me started on ensembling and KFold:\n",
    "# https://machinelearningmastery.com/out-of-fold-predictions-in-machine-learning/\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Clean up our variables - we will be using the xtest_glove_full_scl data\n",
    "X = xtrain_glove_full_scl\n",
    "y = ytrain_full_enc\n",
    "test_X = xtest_glove_full_scl\n",
    "\n",
    "all_cv_X, all_cv_y, all_cv_predict_y, all_test_predict_y = list(), list(), list(), list()\n",
    "\n",
    "# Create our folds...\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# For each fold (n_splits)\n",
    "for train_idx, cv_idx in kfold.split(xtrain_full_glove_np):\n",
    "    # Get our data for our fold\n",
    "    train_X, cv_X = X[train_idx], X[cv_idx]\n",
    "    train_y, cv_y = y[train_idx], y[cv_idx]\n",
    "    \n",
    "    # Save our validation values\n",
    "    all_cv_X.extend(cv_X)\n",
    "    all_cv_y.extend(cv_y)\n",
    "    \n",
    "    # Train our model\n",
    "    model = create_new_model(X.shape[1])\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_f1_m', mode='max', patience=10)\n",
    "    model.fit(train_X, y=train_y, batch_size=64, \n",
    "              epochs=500, verbose=1, \n",
    "              validation_data=(cv_X, cv_y),\n",
    "              callbacks=[early_stop])\n",
    "    \n",
    "    # Get our predictions from the validation set of our fold\n",
    "    all_cv_predict_y.extend(model.predict(cv_X)[:, 1])\n",
    "    all_test_predict_y.append(model.predict(test_X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I have a few options:\n",
    " 1) I could squish results stored in `all_test_predict_y` which is 10 x N stack of results into a single array of results using something like a mean().\n",
    " 2) I could create a new model (e.g. LogisticRegression) and train it on the entire X set (which would be fully contained in `all_cv_X`) plus predicted values of each model (`all_cv_predict_y`).\n",
    " \n",
    "This latter approach is what the article referenced above does but I don't understand it.  It seems like a waste of a trained model to only predict a porition of the know values.  I think a better approach is perhaps a combination of the two above.  In this case, I'll do #2 but then use the output as another dataset to be added to `all_test_predict_y` and then I'll do #1 and squish the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a new X array with 1 new value: the prediction from one of the fold's model\n",
    "all_cv_predict_y = np.array(all_cv_predict_y).reshape((len(all_cv_predict_y), 1))\n",
    "all_new_X = np.hstack((all_cv_X, all_cv_predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 201)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_new_X.shape)\n",
    "display(ytrain_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=150, n_jobs=10, nthread=10, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.7,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = xgb.XGBClassifier(max_depth=6, n_estimators=150, colsample_bytree=0.6,   # Result: 0.7554691298006806\n",
    "                        subsample=0.7, nthread=10, learning_rate=0.1)\n",
    "\n",
    "clf.fit(all_new_X, ytrain_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16267073, -0.24238169, -1.62942518, ...,  1.02434219,\n",
       "        -0.27329935,  0.66620982],\n",
       "       [-0.35180043, -0.1726049 , -0.00423753, ...,  1.11414845,\n",
       "        -0.06431846,  0.95568526],\n",
       "       [-2.39778753, -1.30695824,  0.87201592, ...,  0.4650893 ,\n",
       "        -1.0122227 ,  0.86577904],\n",
       "       ...,\n",
       "       [-0.44700559, -0.6433885 , -0.40905219, ..., -0.55685054,\n",
       "        -0.359125  ,  0.99655342],\n",
       "       [ 0.83638428,  0.27574715, -2.36703299, ..., -1.32417711,\n",
       "         1.39176638,  0.84550333],\n",
       "       [-0.29352605, -0.99998761, -0.0707754 , ...,  0.31688435,\n",
       "         2.60436288,  0.29316145]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of predictions to a matrix get the mean values across all predictions\n",
    "avg_test_y = np.array(all_test_predict_y).mean(0)\n",
    "\n",
    "# Convert the above list into vector\n",
    "all_new_test_predict_y = np.array(avg_test_y).reshape((len(avg_test_y), 1))\n",
    "\n",
    "# stack it with the xtest_glove_full_scl\n",
    "all_new_test_X = np.hstack((xtest_glove_full_scl, all_new_test_predict_y))\n",
    "all_new_test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the XGBoost model trained on the ensembling of the multiple deep learning models each trained on subset of the validation data\n",
    "predictions_1 = clf.predict(all_new_test_X)\n",
    "predictions_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': test_df.id, 'target': predictions_1})\n",
    "output.to_csv('my_submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did terrible!  Score was 0.55562.  Not much better than guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the average of the multiple deep learning models\n",
    "predictions_2 = np.round(avg_test_y).astype(int)\n",
    "predictions_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': test_df.id, 'target': predictions_2})\n",
    "output.to_csv('my_submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one did pretty well: 0.82010\n",
    "\n",
    "Let's try another way to get with method 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6078 - acc: 0.7450 - f1_m: 0.7451 - precision_m: 0.7451 - recall_m: 0.7451\n",
      "Epoch 2/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.4771 - acc: 0.7914 - f1_m: 0.7914 - precision_m: 0.7914 - recall_m: 0.7914\n",
      "Epoch 3/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.4378 - acc: 0.8048 - f1_m: 0.8048 - precision_m: 0.8048 - recall_m: 0.8048\n",
      "Epoch 4/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.4060 - acc: 0.8235 - f1_m: 0.8235 - precision_m: 0.8235 - recall_m: 0.8235\n",
      "Epoch 5/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3979 - acc: 0.8298 - f1_m: 0.8298 - precision_m: 0.8298 - recall_m: 0.8298\n",
      "Epoch 6/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3853 - acc: 0.8303 - f1_m: 0.8303 - precision_m: 0.8303 - recall_m: 0.8303\n",
      "Epoch 7/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3756 - acc: 0.8379 - f1_m: 0.8379 - precision_m: 0.8379 - recall_m: 0.8379\n",
      "Epoch 8/500\n",
      "119/119 [==============================] - ETA: 0s - loss: 0.3620 - acc: 0.8499 - f1_m: 0.8499 - precision_m: 0.8499 - recall_m: 0.849 - 0s 2ms/step - loss: 0.3622 - acc: 0.8492 - f1_m: 0.8492 - precision_m: 0.8492 - recall_m: 0.8492\n",
      "Epoch 9/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3525 - acc: 0.8450 - f1_m: 0.8450 - precision_m: 0.8450 - recall_m: 0.8450\n",
      "Epoch 10/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.8563 - f1_m: 0.8563 - precision_m: 0.8563 - recall_m: 0.8563\n",
      "Epoch 11/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3317 - acc: 0.8604 - f1_m: 0.8604 - precision_m: 0.8604 - recall_m: 0.8604\n",
      "Epoch 12/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3245 - acc: 0.8612 - f1_m: 0.8612 - precision_m: 0.8612 - recall_m: 0.8612\n",
      "Epoch 13/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3183 - acc: 0.8651 - f1_m: 0.8651 - precision_m: 0.8651 - recall_m: 0.8651\n",
      "Epoch 14/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2993 - acc: 0.8760 - f1_m: 0.8760 - precision_m: 0.8760 - recall_m: 0.8760\n",
      "Epoch 15/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2847 - acc: 0.8828 - f1_m: 0.8828 - precision_m: 0.8828 - recall_m: 0.8828\n",
      "Epoch 16/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2887 - acc: 0.8782 - f1_m: 0.8782 - precision_m: 0.8782 - recall_m: 0.8782\n",
      "Epoch 17/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2753 - acc: 0.8841 - f1_m: 0.8842 - precision_m: 0.8842 - recall_m: 0.8842\n",
      "Epoch 18/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2601 - acc: 0.8935 - f1_m: 0.8935 - precision_m: 0.8935 - recall_m: 0.8935\n",
      "Epoch 19/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2399 - acc: 0.9007 - f1_m: 0.9007 - precision_m: 0.9007 - recall_m: 0.9007\n",
      "Epoch 20/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2515 - acc: 0.8957 - f1_m: 0.8957 - precision_m: 0.8957 - recall_m: 0.8957\n",
      "Epoch 21/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2381 - acc: 0.9024 - f1_m: 0.9024 - precision_m: 0.9024 - recall_m: 0.9024\n",
      "Epoch 22/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2254 - acc: 0.9060 - f1_m: 0.9059 - precision_m: 0.9059 - recall_m: 0.9059\n",
      "Epoch 23/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2352 - acc: 0.9033 - f1_m: 0.9033 - precision_m: 0.9033 - recall_m: 0.9033\n",
      "Epoch 24/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2152 - acc: 0.9141 - f1_m: 0.9141 - precision_m: 0.9141 - recall_m: 0.9141\n",
      "Epoch 25/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2119 - acc: 0.9158 - f1_m: 0.9158 - precision_m: 0.9158 - recall_m: 0.9158\n",
      "Epoch 26/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2049 - acc: 0.9138 - f1_m: 0.9138 - precision_m: 0.9138 - recall_m: 0.9138\n",
      "Epoch 27/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2026 - acc: 0.9190 - f1_m: 0.9190 - precision_m: 0.9190 - recall_m: 0.9190\n",
      "Epoch 28/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1977 - acc: 0.9196 - f1_m: 0.9196 - precision_m: 0.9196 - recall_m: 0.9196\n",
      "Epoch 29/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1945 - acc: 0.9203 - f1_m: 0.9203 - precision_m: 0.9203 - recall_m: 0.9203\n",
      "Epoch 30/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1839 - acc: 0.9260 - f1_m: 0.9260 - precision_m: 0.9260 - recall_m: 0.9260\n",
      "Epoch 31/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1715 - acc: 0.9296 - f1_m: 0.9296 - precision_m: 0.9296 - recall_m: 0.9296\n",
      "Epoch 32/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1719 - acc: 0.9346 - f1_m: 0.9345 - precision_m: 0.9345 - recall_m: 0.9345\n",
      "Epoch 33/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1750 - acc: 0.9257 - f1_m: 0.9257 - precision_m: 0.9257 - recall_m: 0.9257\n",
      "Epoch 34/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1671 - acc: 0.9334 - f1_m: 0.9334 - precision_m: 0.9334 - recall_m: 0.9334\n",
      "Epoch 35/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1663 - acc: 0.9339 - f1_m: 0.9339 - precision_m: 0.9339 - recall_m: 0.9339\n",
      "Epoch 36/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1662 - acc: 0.9337 - f1_m: 0.9337 - precision_m: 0.9337 - recall_m: 0.9337\n",
      "Epoch 37/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1674 - acc: 0.9350 - f1_m: 0.9350 - precision_m: 0.9350 - recall_m: 0.9350\n",
      "Epoch 38/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1549 - acc: 0.9394 - f1_m: 0.9394 - precision_m: 0.9394 - recall_m: 0.9394\n",
      "Epoch 39/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1609 - acc: 0.9366 - f1_m: 0.9365 - precision_m: 0.9365 - recall_m: 0.9365\n",
      "Epoch 40/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1498 - acc: 0.9401 - f1_m: 0.9401 - precision_m: 0.9401 - recall_m: 0.9401\n",
      "Epoch 41/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1520 - acc: 0.9385 - f1_m: 0.9385 - precision_m: 0.9385 - recall_m: 0.9385\n",
      "Epoch 42/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1454 - acc: 0.9400 - f1_m: 0.9400 - precision_m: 0.9400 - recall_m: 0.9400\n",
      "Epoch 43/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1407 - acc: 0.9454 - f1_m: 0.9454 - precision_m: 0.9454 - recall_m: 0.9454\n",
      "Epoch 44/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1455 - acc: 0.9422 - f1_m: 0.9422 - precision_m: 0.9422 - recall_m: 0.9422\n",
      "Epoch 45/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1422 - acc: 0.9418 - f1_m: 0.9418 - precision_m: 0.9418 - recall_m: 0.9418\n",
      "Epoch 46/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1416 - acc: 0.9384 - f1_m: 0.9384 - precision_m: 0.9384 - recall_m: 0.9384\n",
      "Epoch 47/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1349 - acc: 0.9458 - f1_m: 0.9458 - precision_m: 0.9458 - recall_m: 0.9458\n",
      "Epoch 48/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1387 - acc: 0.9465 - f1_m: 0.9465 - precision_m: 0.9465 - recall_m: 0.9465\n",
      "Epoch 49/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1320 - acc: 0.9492 - f1_m: 0.9492 - precision_m: 0.9492 - recall_m: 0.9492\n",
      "Epoch 50/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1370 - acc: 0.9429 - f1_m: 0.9429 - precision_m: 0.9429 - recall_m: 0.9429\n",
      "Epoch 51/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1290 - acc: 0.9463 - f1_m: 0.9463 - precision_m: 0.9463 - recall_m: 0.9463\n",
      "Epoch 52/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1262 - acc: 0.9513 - f1_m: 0.9513 - precision_m: 0.9513 - recall_m: 0.9513\n",
      "Epoch 53/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1284 - acc: 0.9498 - f1_m: 0.9498 - precision_m: 0.9498 - recall_m: 0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1319 - acc: 0.9464 - f1_m: 0.9464 - precision_m: 0.9464 - recall_m: 0.9464\n",
      "Epoch 55/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1244 - acc: 0.9509 - f1_m: 0.9509 - precision_m: 0.9509 - recall_m: 0.9509\n",
      "Epoch 56/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1237 - acc: 0.9482 - f1_m: 0.9483 - precision_m: 0.9483 - recall_m: 0.9483\n",
      "Epoch 57/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1247 - acc: 0.9531 - f1_m: 0.9531 - precision_m: 0.9531 - recall_m: 0.9531\n",
      "Epoch 58/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1122 - acc: 0.9548 - f1_m: 0.9548 - precision_m: 0.9548 - recall_m: 0.9548\n",
      "Epoch 59/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1157 - acc: 0.9530 - f1_m: 0.9530 - precision_m: 0.9530 - recall_m: 0.9530\n",
      "Epoch 60/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1188 - acc: 0.9526 - f1_m: 0.9526 - precision_m: 0.9526 - recall_m: 0.9526\n",
      "Epoch 61/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1186 - acc: 0.9542 - f1_m: 0.9542 - precision_m: 0.9542 - recall_m: 0.9542\n",
      "Epoch 62/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1162 - acc: 0.9526 - f1_m: 0.9526 - precision_m: 0.9526 - recall_m: 0.9526\n",
      "Epoch 63/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1040 - acc: 0.9598 - f1_m: 0.9598 - precision_m: 0.9598 - recall_m: 0.9598\n",
      "Epoch 64/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1275 - acc: 0.9485 - f1_m: 0.9485 - precision_m: 0.9485 - recall_m: 0.9485\n",
      "Epoch 65/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1168 - acc: 0.9551 - f1_m: 0.9551 - precision_m: 0.9551 - recall_m: 0.9551\n",
      "Epoch 66/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1159 - acc: 0.9556 - f1_m: 0.9556 - precision_m: 0.9556 - recall_m: 0.9556\n",
      "Epoch 67/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1037 - acc: 0.9626 - f1_m: 0.9626 - precision_m: 0.9626 - recall_m: 0.9626\n",
      "Epoch 68/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1060 - acc: 0.9589 - f1_m: 0.9589 - precision_m: 0.9589 - recall_m: 0.9589\n",
      "Epoch 69/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1111 - acc: 0.9543 - f1_m: 0.9543 - precision_m: 0.9543 - recall_m: 0.9543\n",
      "Epoch 70/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1019 - acc: 0.9614 - f1_m: 0.9614 - precision_m: 0.9614 - recall_m: 0.9614\n",
      "Epoch 71/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1126 - acc: 0.9532 - f1_m: 0.9532 - precision_m: 0.9532 - recall_m: 0.9532\n",
      "Epoch 72/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1074 - acc: 0.9568 - f1_m: 0.9568 - precision_m: 0.9568 - recall_m: 0.9568\n",
      "Epoch 73/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1020 - acc: 0.9578 - f1_m: 0.9578 - precision_m: 0.9578 - recall_m: 0.9578\n",
      "Epoch 74/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1047 - acc: 0.9595 - f1_m: 0.9595 - precision_m: 0.9595 - recall_m: 0.9595\n",
      "Epoch 75/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1019 - acc: 0.9584 - f1_m: 0.9584 - precision_m: 0.9584 - recall_m: 0.9584\n",
      "Epoch 76/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0954 - acc: 0.9614 - f1_m: 0.9614 - precision_m: 0.9614 - recall_m: 0.9614\n",
      "Epoch 77/500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.1143 - acc: 0.9557 - f1_m: 0.9557 - precision_m: 0.9557 - recall_m: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2453ba989c8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = create_new_model(X.shape[1])\n",
    "early_stop = callbacks.EarlyStopping(monitor='f1_m', mode='max', patience=10)\n",
    "test_model.fit(X, y=y, batch_size=64, \n",
    "          epochs=500, verbose=1,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42130402, 0.9956761 , 0.5831366 , ..., 0.99970514, 0.9995189 ,\n",
       "       0.23291433], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = test_model.predict(xtest_glove_full_scl)[:, 1]\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16267073, -0.24238169, -1.62942518, ...,  1.02434219,\n",
       "        -0.27329935,  0.42130402],\n",
       "       [-0.35180043, -0.1726049 , -0.00423753, ...,  1.11414845,\n",
       "        -0.06431846,  0.9956761 ],\n",
       "       [-2.39778753, -1.30695824,  0.87201592, ...,  0.4650893 ,\n",
       "        -1.0122227 ,  0.58313662],\n",
       "       ...,\n",
       "       [-0.44700559, -0.6433885 , -0.40905219, ..., -0.55685054,\n",
       "        -0.359125  ,  0.99970514],\n",
       "       [ 0.83638428,  0.27574715, -2.36703299, ..., -1.32417711,\n",
       "         1.39176638,  0.99951887],\n",
       "       [-0.29352605, -0.99998761, -0.0707754 , ...,  0.31688435,\n",
       "         2.60436288,  0.23291433]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the above list into vector\n",
    "all_new_test_predict_y = np.array(test_predictions).reshape((len(test_predictions), 1))\n",
    "\n",
    "# stack it with the xtest_glove_full_scl\n",
    "all_new_test_X = np.hstack((xtest_glove_full_scl, all_new_test_predict_y))\n",
    "all_new_test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the XGBoost model trained on the ensembling of the multiple deep learning models each trained on subset of the validation data\n",
    "predictions_1b = clf.predict(all_new_test_X)\n",
    "predictions_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': test_df.id, 'target': predictions_1b})\n",
    "output.to_csv('my_submission_1b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow was this one bad... 0.52589.  It's not working at all and I think it's due to the NN's randomness on each start.  I should look into using a seed to see if that randomness can be avoided because it's really throwing off the XGBoost's ability to learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
